---
layout:     post			# 使用的布局（不需要改）
title:      Day2-多元线性回归		# 标题 
subtitle:   Coursera机器学习课程        	# 副标题
date:       2018-09-29			# 时间
author:     RavenZhao 			# 作者
header-img: img/post-bg-2015.jpg 	# 这篇文章标题背景图片
catalog: true 				# 是否归档
tags:					# 标签
- 机器学习
- 笔记
- Coursera

---

# Day 2.多元线性回归

### 多元线性回归

- 多元线性回归假设：$h_{\theta}(x)=\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n$
  - 定义$x_0=1$
  - $x=\begin{bmatrix}x_0\\x_1\\x_2\\\vdots\\x_n\end{bmatrix}$
  - $\theta=\begin{bmatrix}\theta_0\\\theta_1\\\theta_2\\\vdots\\\theta_n\end{bmatrix}$
  - $h_{\theta}(x)=\theta^Tx$
  - 代价函数$J(\theta)=\frac1{2m}\sum_{i=1}^m(h_{\theta}(x^{\{i\}})-y^{\{i\}})^2$
  - 梯度下降：$\theta_j:=\theta_j-\alpha\frac{\part}{\part\theta_j}J(\theta)$

- 特征缩放（feature scaling）
  - 将不同的特征的取值调整到$-1\leq x_i\leq 1$内，可以使梯度下降更快收敛；
  - 一般情况下，将一个特征值的范围调整到[-3,+3]之间，比较合适。
- 归一化（Mean normalization）
  - $x_i=\frac{x_i-\mu_i}{x_{imax}-x_{imin}}$

- 调整学习速率$\alpha$
  - $\alpha$过小，收敛速率很慢
  - $\alpha$过大，代价函数可能无法收敛。

### 多项式回归
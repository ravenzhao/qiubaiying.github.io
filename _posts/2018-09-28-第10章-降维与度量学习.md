---
layout:     post   				# 使用的布局（不需要改）
title:      第十章 降维与度量学习			# 标题 
subtitle:                      			# 副标题
date:       2018-09-28				# 时间
author:     RavenZhao	 			# 作者
header-img: img/post-bg-2015.jpg 	# 这篇文章标题背景图片
catalog: true 						# 是否归档
tags:							# 标签
    - 机器学习
    - 笔记

---

# 第十章 降维与度量学习

### 10.1 k近邻学习

- $k$近邻（k-NearestNeighbor，简称KNN）学习是一种常见的监督学习方法。
  - 给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个“邻居”的信息来进行预测。
  - 在分类任务中常使用“投票法”，即选择这k个样本中出现最多的类别标记作为预测结果；
  - 在回归任务中可使用“平均法”，即将这k个样本的实值输出标记的平均值作为预测结果。
- k近邻学习是“懒惰学习”（lazy learning）的代表：在训练阶段仅仅把样本保存起来，待收到测试样本后再进行处理。（在训练阶段就对样本进行学习处理的方法称为“急切学习”eager learning）

![image-20180928215354483](https://ws1.sinaimg.cn/large/006tNc79ly1fvpli1as9vj30vg0cmn1f.jpg)

- 最近邻分类器虽然简单，但它的繁华错误率不超过贝叶斯最优分类器的错误率的两倍。
---
layout:     post			# 使用的布局（不需要改）
title:      第二周-多元线性回归		# 标题 
subtitle:   Coursera机器学习课程        	# 副标题
date:       2018-09-29			# 时间
author:     RavenZhao 			# 作者
header-img: img/post-bg-2015.jpg 	# 这篇文章标题背景图片
catalog: true 				# 是否归档
tags:					# 标签
- 机器学习
- 笔记
- Coursera

---

# 第二周 多元线性回归

### 多元线性回归

- 多元线性回归假设：$h_{\theta}(x)=\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n$
  - 定义$x_0=1$
  - $x=\begin{bmatrix}x_0\\x_1\\x_2\\\vdots\\x_n\end{bmatrix}$
  - $\theta=\begin{bmatrix}\theta_0\\\theta_1\\\theta_2\\\vdots\\\theta_n\end{bmatrix}$
  - $h_{\theta}(x)=\theta^Tx$
  - 代价函数$J(\theta)=\frac1{2m}\sum_{i=1}^m(h_{\theta}(x^{\{i\}})-y^{\{i\}})^2$
  - 梯度下降：$\theta_j:=\theta_j-\alpha\frac{\part}{\part\theta_j}J(\theta)$

- 特征缩放（feature scaling）
  - 将不同的特征的取值调整到$-1\leq x_i\leq 1$内，可以使梯度下降更快收敛；
  - 一般情况下，将一个特征值的范围调整到[-3,+3]之间，比较合适。
- 归一化（Mean normalization）
  - $x_i=\frac{x_i-\mu_i}{x_{imax}-x_{imin}}$

- 调整学习速率$\alpha$
  - $\alpha$过小，收敛速率很慢
  - $\alpha$过大，代价函数可能无法收敛。

### 正规方程

- 用正规方程**直接**求解线性回归参数$\theta$的最优值。

	- 梯度下降法使用迭代方式计算代价函数的全局最小值。

- 假设$J(\theta)=a\theta^2+b\theta+c$

	- $\frac{\part}{\part\theta_i}J(\theta)=0$
	- $\theta=(X^TX)^{-1}X^Ty$为能使代价函数最小化的$\theta$值

- 假设样本包含$m$个样本$\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\}$，每个样本包含$n$个特征：$x^{(i)}=\begin{bmatrix}x_0^{(i)} \\ x_1^{(i)} \\ \vdots \\ x_n^{(i)}\end{bmatrix}\in\mathbb{R^{n+1}}$

	- 设计矩阵（design matrix）$X=\begin{bmatrix}{x^{(1)}}^T \\ {x^{(2)}}^T \\ \vdots \\ {x^{(m)}}^T\end{bmatrix}$，为一个$m\times(n+1)$矩阵

	- 如果$x^{(i)}=\begin{bmatrix}1 \\ x_1^{(i)}\end{bmatrix}$，则$X=\begin{bmatrix}1&x_1^{(1)} \\ 1&x_1^{(2)} \\ \vdots&\vdots \\ 1&x_1^{(m)}\end{bmatrix}$

	- Octave代码计算$(X^TX)^{-1}X^Ty$为：

		```octave
		pinv(X'*X)*X'*y
		```

- 采用正规方程法可以不对特征进行归一化。

| 参数求解方法 | 优点                         | 缺点                                                         |
| ------------ | ---------------------------- | ------------------------------------------------------------ |
| 梯度下降法   | 特征数量$n$非常庞大时也适用  | 需要选择$\alpha$，迭代次数很多                               |
| 正规方程法   | 不需要选择$\alpha$，无需迭代 | 需要计算$(X^TX)^{-1}$，当特征数量$n$很大（$n\gg10000$）时计算缓慢 |

- 正规方程的不可逆性
	- 如果$X^TX$是不可逆矩阵，查看是否存在冗余特征，将其删除。 
	- 可能特征数量太多，删除部分。
---
layout:     post			# 使用的布局（不需要改）
title:      Day3-正规方程		# 标题 
subtitle:   Coursera机器学习课程        	# 副标题
date:       2018-09-30			# 时间
author:     RavenZhao 			# 作者
header-img: img/post-bg-2015.jpg 	# 这篇文章标题背景图片
catalog: true 				# 是否归档
tags:					# 标签
- 机器学习
- 笔记
- Coursera


---

# Day 3.正规方程

- 用正规方程**直接**求解线性回归参数$\theta$的最优值。

  - 梯度下降法使用迭代方式计算代价函数的全局最小值。

- 假设$J(\theta)=a\theta^2+b\theta+c$

  - $\frac{\part}{\part\theta_i}J(\theta)=0$
  - $\theta=(X^TX)^{-1}X^Ty$为能使代价函数最小化的$\theta$值

- 假设样本包含$m$个样本$\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\}$，每个样本包含$n$个特征：$x^{(i)}=\begin{bmatrix}x_0^{(i)}\\ x_1^{(i)}\\ \vdots\\ x_n^{(i)}\end{bmatrix}\in\mathbb{R^{n+1}}$

  - 设计矩阵（design matrix）$X=\begin{bmatrix}{x^{(1)}}^T\\ {x^{(2)}}^T\\ \vdots\\ {x^{(m)}}^T\end{bmatrix}$，为一个$m\times(n+1)$矩阵

  - 如果$x^{(i)}=\begin{bmatrix}1\\ x_1^{(i)}\end{bmatrix}​$，则$X=\begin{bmatrix}1&x_1^{(1)}\\ 1&x_1^{(2)}\\ \vdots&\vdots\\ 1&x_1^{(m)}\end{bmatrix}​$

  - Octave代码计算$(X^TX)^{-1}X^Ty$为：

    ```octave
    pinv(X'*X)*X'*y
    ```

- 采用正规方程法可以不对特征进行归一化。

| 参数求解方法 | 优点                         | 缺点                                                         |
| ------------ | ---------------------------- | ------------------------------------------------------------ |
| 梯度下降法   | 特征数量$n$非常庞大时也适用  | 需要选择$\alpha$，迭代次数很多                               |
| 正规方程法   | 不需要选择$\alpha$，无需迭代 | 需要计算$(X^TX)^{-1}$，当特征数量$n$很大（$n\gg10000$）时计算缓慢 |


---
layout:     post   				    # 使用的布局（不需要改）
title:      第五章 神经网络		# 标题 
subtitle:                            #副标题
date:       2018-09-01 				# 时间
author:     RavenZhao 						# 作者
header-img: img/post-bg-2015.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 机器学习
    - 笔记
---

# 第五章 神经网络

### 5.1 神经元模型

> 神经网络是由具有适应性的简单单元组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。

- 神经元（neuron）模型：神经网络中最基本的成分。“简单单元”
  - 连接（connection）
  - 激活函数（activation function）：
    - 理想的激活函数是阶跃函数，它将输入值映射为输出值“0”或“1”，1对应神经元兴奋，0对应神经元抑制。
    - 阶跃函数不连续、不光滑，因此常用Sigmoid函数作为激活函数。它把可能在较大范围内变化的输入值挤压到（0，1）输出值范围内，有时也称为“挤压函数”（squashing function）

![image-20180828212415273](assets/image-20180828212415273.png)

![image-20180828211809184](assets/image-20180828211809184.png)

### 5.2 感知机与多层网络

- 感知机（Perceptron）由两层神经元组成。

  - 输入层接收外界输入信号后，传递给输出层。
  - 输出层是M-P神经元，亦称“阈值逻辑单元”（threshold logic unit）
  - 感知机能容易地实现逻辑与、或、非运算。由$y=f(\sum_iw_ix_i-\theta)$，假定$f$是阶跃函数：
    - “与”$(x_1 \and x_2)$：令$w_1=w_2=1,\theta=2$，则$y=f(1·x_1+1·x_2-2)$，仅在$x_1=x_2=1$时，$y=1$；
    - “或”$(x_1 \or x_2)$：令$w_1=w_2=1,\theta=0.5$，则$y=f(1·x_1+1·x_2-0.5)$，仅在$x_1$或$x_2=1$时，$y=1$；
    - “非”$(-x_1)$：令$w_1=-0.6,w_2=0,\theta=-0.5$，则$y=f(-0.6·x_1+0·x_2+0.5)$，当$x_1=1$时，$y=0$，当$x_1=0$时，$y=1$
  - 更一般地，给定训练数据集，权重$w_i(i=1,2,...,n)$以及阈值$\theta$可通过学习得到，阈值$\theta$可看做一个固定输入为-1.0的哑结点（dummy node）所对应的连接权重$w_{n+1}$。这样，权重和阈值的学习就可统一为权重的学习。
  - 感知机的学习规则非常简单，对训练样例$(x,y)$，若当前感知机的输出为$\bar y$，则感知机权重将这样调整：$w_i\gets w_i+\Delta w_i$，$\Delta w_i=\eta(y-\bar y)w_i$
    - $\eta \in(0,1)$为学习率（Learning rate）。
    - 若感知机对训练样例$(x,y)$预测正确，即$\hat y=y$，则感知机不发生变化，否则将根据错误的程度进行权重调整。

  ![image-20180828212517698](assets/image-20180828212517698.png)

  - 感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元（functional neuron），学习能力十分有限。与、或、非问题都是线性可分（linearly separable）问题。
  - 要解决非线性可分问题，需考虑使用多层功能神经元。
    - 输出层与输入层之间的一层神经元，被称为隐层或隐含层（hidden layer）。隐含层和输出层神经元都是拥有激活函数的功能神经元。
  - 一般情况下，每层神经元与下一层神经元完全互连，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络结构通常称为“多层前馈神经网络”（multi-layer feedforward neural networks）
    - 输入层神经元接收外界输入
    - 隐层和输出层神经元对信号进行加工
    - 最终结果由输出层神经元输出。
    - 神经网络的学习过程，就是根据训练数据来调整神经元之间的**“连接权”**（connection weight）以及每个功能神经元的**阈值**；

  ![image-20180828215003004](assets/image-20180828215003004.png)

### 5.3 误差逆传播算法

- 误差逆传播算法（error BackPropagation）是多层网络学习的杰出代表。
- 给定训练集$D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\},x_i\in R^d,y_i \in R^l$，即输入示例由$d$个属性描述，输出$l$维值向量。
  - 对训练例$(x_k,y_k)$，假定神经网络的输出为$\hat y_k=(\hat y_1^k,\hat y_2^k,...,\hat y_l^k)$，即$\hat y_j^k=f(\beta_j-\theta_j)$
  - 则网络在$(x_k,y_k)$上的均方误差为：$E_k=\frac12\sum_{j=1}^l(\hat y_j^k-y_j^k)^2$
  - 网络中有$(d+l+1)q+l$个参数需要确定：
    - 输入层到隐层的$d×q$个权值；
    - 隐层到输出层的$q×l$个权值；
    - $q$个隐层神经元的阈值；
    - $l$个输出层神经元的阈值。

![image-20180828215622218](assets/image-20180828215622218.png)

- BP是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计，任意参数$v$的更新估计式为：$v\gets v+\Delta v$
  - BP算法基于梯度下降（Gradient Descent）策略，以目标函数的负梯度方向对参数进行调整，给定学习率$\eta$，有$\Delta w_{hj}=-\eta \frac{\partial E_k}{\partial w_{hj}}$
  - $w_{hj}$先影响到第$j$个输出层神经元的输入值$\beta_j$，再影响到其输出值$\hat y_j^k$，然后影响到$E_k$，即$\frac{\partial E_k}{\partial w_{hj}}=\frac{\partial E_k}{\partial\hat y_j^k}·\frac{\partial\hat y_j^k}{\partial\beta_j}·\frac{\partial\beta_j}{\partial w_{hj}}$
  - 根据$\beta_j$的定义，$\frac{\partial\beta_j}{\partial w_{hj}}=b_h$
  - Sigmoid函数有一个很好的性质：$f'(x)=f(x)(1-f(x))$
  - $g_i=-\frac{\partial E_k}{\partial\hat y_j^k}·\frac{\partial\hat y_j^k}{\partial\beta_j}=-(\hat y_j^k-y_j^k)f'(\beta_j-\theta_j)=\hat y_j^k(1-\hat y_j^k)(y_j^k-\hat y_j^k)$
  - $\Delta w_{hj}=\eta g_jb_h$
  - $\Delta \theta_j=-\eta g_j$，$\Delta v_{ih}=\eta e_hx_i$，$\Delta \gamma_h=-\eta e_h$
  - $e_h=-\frac{\partial E_k}{\partial b_h}·\frac{\partial b_h}{\partial \alpha_h}=-\sum_{j=1}^l\frac{\partial E_k}{\partial \beta_j}·\frac{\partial \beta_j}{\partial b_h}f'(\alpha_h-\gamma_h)=\sum_{j=1}^lw_{hj}g_jf'(\alpha_h-\gamma_h)=b_h(1-b_h)\sum_{j=1}^lw_{hj}g_j$

![image-20180828222024507](assets/image-20180828222024507.png)

- 学习率$\eta \in (0,1)$控制着算法每一轮迭代中的更新步长，若太大容易震荡，若太小容易收敛速度过慢。
- BP算法的目标是最小化训练集$D$上的**积累误差**$E=\frac1m\sum_{k=1}^mE_k$
- 标准BP算法每次仅针对一个训练样例更新连接权和阈值。如果推导基于积累误差最小化的更新规则，就得到积累误差逆传播算法。

### 5.4 全局最小与局部极小

- $E$表示神经网络在训练集上的误差，是关于连接权$w$和阈值$\theta$的函数。
- 神经网络的训练过程可以看做一个参数寻优的过程，在参数空间中，寻找一组最优参数使得$E$最小。
- 对$w^*$和$\theta^*$，如果存在$\epsilon>0$使得$\forall (w;\theta)\in\{(w;\theta)|\lVert (w;\theta)-(w^*;\theta^*)\rVert\leq\epsilon\}$，都有$E(w;\theta)\geq E(w^*;\theta^*)$成立，则$(w^*;\theta^*)$为局部极小（local minimum）解。
  - 局部极小解是参数空间中的某个点，其**邻域点**的误差函数值均不小于该点的函数值。
  - 参数空间内梯度为零的点，只要其误差函数值小于邻点的误差函数值，就是局部极小点，可能会存在多个局部极小点。
- 若对参数空间中的任意$(w;\theta)$，都有$E(w;\theta)\geq E(w^*;\theta^*)$，则$(w^*;\theta^*)$为全局最小（global minimum）解。
  - 全局最小解则是指参数空间中**所有的点**的误差函数指均不小于该店的误差函数指。
  - 全局最小解只有一个，全局最小一定是局部极小。

![image-20180830213733111](assets/image-20180830213733111.png)

- 基于梯度的搜索是使用最广泛的参数寻优方法。从某些初始解出发，迭代寻找最优参数值。
  - 每次迭代中，先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向。
  - 如果误差函数在当前点的梯度为零，则以达到局部极小，更新量降为零，参数的迭代更新在此停止。
  - 如果误差函数仅有一个局部极小，那么此时的局部极小就是全局最小。
  - 如果误差函数有多个局部极小，则不能保证找得到的解释全局最小。
- 现实任务中，人们试图“跳出”局部极小，从而进一步接近全局最小：
  - 以多组不同参数值初始化多个神经网络，按标准方法训练后，取其误差最小的解作为最终参数。这相当于于从多个不同的初始点开始搜索，可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。
  - 使用“模拟退火”（simulated annealing）技术模拟退火在每一步都以一定的概率接受比当前更差的结果，从而有助于“跳出”局部极小。在每步迭代过程中，接受“次优解”的概率要随着时间的推移而逐渐降低，从而保证算法稳定。
  - 使用随机梯度下降，与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了随机因素，于是，即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索。

### 5.5 其他常见神经网络

#### 5.5.1 RBF网络

RBF（Radial Basis Function，径向基函数）网络是一种单隐层前馈神经网络，使用径向基函数作为隐层神经元激活函数，输出层是对神经元输出的线性组合。

#### 5.5.2 ART网络

- 竞争型学习（competitive learning）是神经网络中一种常见的无监督学习策略。使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜神经元被激活，其他神经元的状态被抑制，这种机制被称为“胜者通吃”（winner-take-all）原则。
- ART（Adaptive Resonance Theory，自适应谐振理论）网络是竞争型学习的代表。该网络由比较层、识别层、识别阈值和重置模块构成。

#### 5.5.3 SOM网络

- SOM网络（Self-Organizing Map，自组织映射）网络是一种竞争学习型的无监督神经网络，它能将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构。即将高维空间中相似的样本点映射到网络输出层中的邻近神经元

### 5.6 深度学习

- 参数越多的模型复杂度越高，容量越大，能完成更复杂的学习任务。但是复杂模型的训练效率低，容易陷入过拟合。
- 复杂模型的代表深度学习。
- 典型的深度学习模型就是很深层的神经网络。
  - 对神经网络模型，提高容量的一个简单办法是增加隐层的数目，隐层多了，相应的神经元连接权、阈值等参数就会更多，模型复杂度也可以通过单纯增加隐层神经元的数目来实现。
  - 增加隐层数目不仅增加了拥有激活函数的神经元数目，还增加了激活函数嵌套的层数，效果比增加隐层神经元数目更有效。但是多隐层网络难以直接用经典算法进行训练，因为误差在多隐层内逆传播时，往往会发散二不能收敛到稳定状态。
  - 无监督逐层训练（unsupervised layer-wise training）是多隐层网络训练的有效手段，其基本思想是每次训练一层隐结点，训练时将上一层隐结点的输出作为输入，而本层隐结点的输出作为下一层隐结点的输入，这称为“预训练”（pre-training）；在预训练全部完成后，再对整个网络进行微调（fine-tuning）训练。

